{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwaLCBAIWHiV/SEBW7of8s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aradhyakapil/RAG-Streamlit-app/blob/main/2_RAG_streamlit_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYdB-2dbXUzq"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "from openai import OpenAI\n",
        "from PyPDF2 import PdfReader\n",
        "from sentence_splitter import SentenceSplitter\n",
        "import numpy as np\n",
        "import faiss\n",
        "from io import BytesIO\n",
        "\n",
        "st.sidebar.title(\"ðŸ” OpenAI API Key\")\n",
        "api_key = st.sidebar.text_input(\"Enter your OpenAI API key\", type=\"password\")\n",
        "if not api_key:\n",
        "    st.warning(\"Please provide the key in the sidebar.\")\n",
        "    st.stop()\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "needed_keys = [\"pdf_bytes\", \"chunks\", \"embeddings\", \"index\", \"messages\"]\n",
        "for k in needed_keys:\n",
        "    if k not in st.session_state:\n",
        "        st.session_state[k] = None\n",
        "if st.session_state.messages is None:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "def extract_text_from_pdf(file_like):\n",
        "    reader = PdfReader(file_like)\n",
        "    return \"\\n\".join(p.extract_text() for p in reader.pages if p.extract_text())\n",
        "\n",
        "def chunk(text, size=500):\n",
        "    splitter = SentenceSplitter(language=\"en\")\n",
        "    buf, out = \"\", []\n",
        "    for sent in splitter.split(text):\n",
        "        buf = f\"{buf}{sent} \"\n",
        "        if len(buf) >= size:\n",
        "            out.append(buf.strip()); buf = \"\"\n",
        "    if buf: out.append(buf.strip())\n",
        "    return out\n",
        "\n",
        "def embed(text_blocks):\n",
        "    res = client.embeddings.create(\n",
        "        model=\"text-embedding-3-small\",\n",
        "        input=text_blocks\n",
        "    )\n",
        "    return np.array([d.embedding for d in res.data])\n",
        "\n",
        "def build_index(embeds):\n",
        "    idx = faiss.IndexFlatL2(embeds.shape[1])\n",
        "    idx.add(embeds)\n",
        "    return idx\n",
        "\n",
        "def top_k_chunks(q, k=3):\n",
        "    q_emb = client.embeddings.create(\n",
        "        model=\"text-embedding-3-small\",\n",
        "        input=[q]\n",
        "    ).data[0].embedding\n",
        "    D, I = st.session_state.index.search(np.array([q_emb]), k)\n",
        "    return [st.session_state.chunks[i] for i in I[0]]\n",
        "\n",
        "def ask_llm(user_q):\n",
        "    context = \"\\n\".join(top_k_chunks(user_q))\n",
        "    messages = (\n",
        "        [{\"role\":\"system\",\n",
        "          \"content\":\"You are a helpful assistant. Use the context to answer.\"}]\n",
        "        + st.session_state.messages[-20:]     # last 20 turns at most\n",
        "        + [{\"role\":\"user\",\n",
        "            \"content\":f\"Context:\\n{context}\\n\\nQuestion: {user_q}\"}]\n",
        "    )\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages\n",
        "    )\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "st.title(\"ðŸ§   RAG Chatbot\")\n",
        "uploaded = st.file_uploader(\"ðŸ“„  Upload a PDF\", type=\"pdf\", key=\"pdf_up\")\n",
        "if uploaded and st.session_state.pdf_bytes is None:\n",
        "    # First time we see this PDF in this session\n",
        "    st.session_state.pdf_bytes = uploaded.read()\n",
        "    with st.spinner(\"Extracting & embedding â€¦\"):\n",
        "        text               = extract_text_from_pdf(BytesIO(st.session_state.pdf_bytes))\n",
        "        st.session_state.chunks = chunk(text)\n",
        "        st.session_state.embeddings = embed(st.session_state.chunks)\n",
        "        st.session_state.index = build_index(st.session_state.embeddings)\n",
        "    st.success(\"Indexed! Ask away ðŸ‘‡\")\n",
        "\n",
        "if st.session_state.pdf_bytes and st.session_state.index is None:\n",
        "    st.session_state.index = build_index(st.session_state.embeddings)\n",
        "\n",
        "\n",
        "if st.session_state.index:\n",
        "    for m in st.session_state.messages:\n",
        "        st.chat_message(m[\"role\"]).markdown(m[\"content\"])\n",
        "\n",
        "    if user_q := st.chat_input(\"Ask a question about the PDF\"):\n",
        "        st.chat_message(\"user\").markdown(user_q)\n",
        "        with st.spinner(\"Thinkingâ€¦\"):\n",
        "            answer = ask_llm(user_q)\n",
        "        st.chat_message(\"assistant\").markdown(answer)\n",
        "\n",
        "        st.session_state.messages += [\n",
        "            {\"role\":\"user\", \"content\":user_q},\n",
        "            {\"role\":\"assistant\", \"content\":answer},\n",
        "        ]\n",
        "else:\n",
        "    st.info(\"Upload a PDF to start chatting.\")\n"
      ]
    }
  ]
}